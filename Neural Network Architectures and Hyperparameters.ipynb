{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a03376d1-7f9f-4dbd-9a5c-b67bf245cf91",
   "metadata": {},
   "source": [
    "## Activation Functions\n",
    "\n",
    "- Activation functions add non-linearity to the network\n",
    "    * **Sigmoid** for binary classification\n",
    "    * **Softmax** for multi-class classification\n",
    "\n",
    "- A network can learn more complex relationships with non-linearity\n",
    "- \"Pre-activation\" output passed to theactivation function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab421c88-6502-4181-8062-cdc8898f6fa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9975]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "input_tensor = torch.tensor([[6]])\n",
    "sigmoid = nn.Sigmoid()\n",
    "output = sigmoid(input_tensor)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b47eaf3f-9238-4791-87c9-73b9f83e91c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(6, 4), # First linear layer\n",
    "    nn.Linear(4, 1), # Second linear layer\n",
    "    nn.Sigmoid() # Sigmoid activation function\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "983e391c-1c83-47bf-8c05-0a2c320ff56b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1392, 0.8420, 0.0188]])\n"
     ]
    }
   ],
   "source": [
    "# Create an input tensor\n",
    "input_tensor = torch.tensor([[4.3, 6.1, 2.3]])\n",
    "\n",
    "# Apply softmax along the last dimension\n",
    "probabilities = nn.Softmax(dim=-1)\n",
    "output_tensor = probabilities(input_tensor)\n",
    "print(output_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc84afa-df18-4be8-a777-0a37a1df2688",
   "metadata": {},
   "source": [
    "**dim = -1** indicates softmax is applied to the input tensor's last dimension\n",
    "**nn.Softmax()** can be used as last step in **nn.Sequential()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fea1b2a-bd0a-4d1d-96fe-81c9cdfe6278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9168]])\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "\n",
    "input_tensor = torch.tensor([[2.4]])\n",
    "\n",
    "# Create a sigmoid function and apply it on input_tensor\n",
    "sigmoid = nn.Sigmoid()\n",
    "probability = sigmoid(input_tensor)\n",
    "print(probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37ea8bab-64ab-470c-9e80-8b68e6f7422a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.2828e-01, 1.1698e-04, 5.7492e-01, 3.4961e-02, 1.5669e-01, 1.0503e-01]])\n"
     ]
    }
   ],
   "source": [
    "# training ver 2\n",
    "\n",
    "input_tensor = torch.tensor([[1.0, -6.0, 2.5, -0.3, 1.2, 0.8]])\n",
    "\n",
    "# Create a softmax function and apply it on input_tensor\n",
    "softmax = nn.Softmax(dim = -1)\n",
    "probabilities = softmax(input_tensor)\n",
    "print(probabilities)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229d4242-4b69-4cb0-a1fe-d7ff8f6e1c5f",
   "metadata": {},
   "source": [
    "## Running a Forward Pass\n",
    "\n",
    "Forward Pass:\n",
    "- Input data flows through layers\n",
    "- Calculations performed at each layer\n",
    "- Final layer generates outputs\n",
    "- Outputs produced based on weights and biases\n",
    "- Used for training and making predictions\n",
    "\n",
    "Possible outputs:\n",
    "- Binary classification\n",
    "- Multi-class classification\n",
    "- Regressions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17dcf9f4-8cc3-4957-a439-079a1cbfd6dd",
   "metadata": {},
   "source": [
    "### Binary Classification: Forward Pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4520dbb-0abf-40c5-a9ec-0ea25621729f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create input data of shape 5x6\n",
    "input_data = torch.tensor(\n",
    " [[-0.4421, 1.5207, 2.0607, -0.3647,  0.4691,  0.0946],\n",
    "  [-0.9155, -0.0475, -1.3645,  0.6336, -1.9520, -0.3398],\n",
    "  [ 0.7406,  1.6763, -0.8511,  0.2432,  0.1123, -0.0633],\n",
    "  [-1.6630, -0.0718, -0.1285,  0.5396, -0.0288, -0.8622],\n",
    "  [-0.7413,  1.7920, -0.0883, -0.6685,  0.4745, -0.4245]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c210f07-219f-42c9-a559-2f624261a969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3420],\n",
      "        [0.6496],\n",
      "        [0.4133],\n",
      "        [0.5792],\n",
      "        [0.3903]], grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Create binary classification model\n",
    "model = nn.Sequential(nn.Linear(6,4), # First linear layer  \n",
    "                      nn.Linear(4,1),# Second linear layer  \n",
    "                      nn.Sigmoid()# Sigmoid activation function\n",
    "                     )\n",
    "\n",
    "# Pass input data through model\n",
    "output = model(input_data)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eccf821-a41e-4691-a491-2e14faf6d397",
   "metadata": {},
   "source": [
    "### Multi-classification: Forward Pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96956e3e-1c96-4cf2-90f6-5fd1a9265a4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3])\n",
      "\n",
      " tensor([[0.2291, 0.5181, 0.2528],\n",
      "        [0.3912, 0.3141, 0.2947],\n",
      "        [0.1658, 0.5470, 0.2872],\n",
      "        [0.3649, 0.3823, 0.2528],\n",
      "        [0.1698, 0.5507, 0.2795]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "n_classes = 3 \n",
    "\n",
    "# Create multi-class classification model\n",
    "model = nn.Sequential(nn.Linear(6,4), # First linear layer  \n",
    "                      nn.Linear(4, n_classes), # Second linear layer  \n",
    "                      nn.Softmax(dim=-1) # Softmax activation \n",
    "                     )\n",
    "\n",
    "# Pass input data through model\n",
    "output = model(input_data)\n",
    "print(output.shape)\n",
    "print(\"\\n\",output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba6f133-6566-4d32-ac5c-4ff4dde598cf",
   "metadata": {},
   "source": [
    "### Regression: Forward Pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ac1cb9d-e381-4269-ad58-a2c3704fd55a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0557],\n",
      "        [ 0.5150],\n",
      "        [-0.3101],\n",
      "        [ 0.7701],\n",
      "        [-0.3550]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Create regression model\n",
    "model = nn.Sequential(nn.Linear(6, 4), # First linear layer  \n",
    "                      nn.Linear(4, 1) # Second linear layer\n",
    "                     ) \n",
    "\n",
    "# Pass input data through model\n",
    "output = model(input_data)\n",
    "\n",
    "# Return output\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7c43819-bbef-4d33-a9d9-f3bdf70c1466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9627]], grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# training ver 3\n",
    "\n",
    "input_tensor = torch.Tensor([[3, 4, 6, 2, 3, 6, 8, 9]])\n",
    "\n",
    "# Implement a small neural network for binary classification\n",
    "model = nn.Sequential(\n",
    "  nn.Linear(8, 1),\n",
    "  nn.Sigmoid()\n",
    ")\n",
    "\n",
    "output = model(input_tensor)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "386e6cdf-f9a7-42c3-a540-8004775217c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.3306]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# training ver 4\n",
    "\n",
    "input_tensor = torch.Tensor([[3, 4, 6, 7, 10, 12, 2, 3, 6, 8, 9]])\n",
    "\n",
    "# Implement a neural network with exactly four linear layers\n",
    "model = nn.Sequential(\n",
    "  nn.Linear(11, 64),   # Layer 1: from 11 input features to 64\n",
    "  nn.Linear(64, 32),   # Layer 2: from 64 to 32\n",
    "  nn.Linear(32, 16),   # Layer 3: from 32 to 16\n",
    "  nn.Linear(16, 1)     # Layer 4: from 16 to 1 output (regression)\n",
    ")\n",
    "\n",
    "output = model(input_tensor)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce732000-bb5b-4179-8792-61b3dd5089e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1137, 0.6410, 0.0748, 0.1706]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# training ver 5\n",
    "\n",
    "input_tensor = torch.Tensor([[3, 4, 6, 7, 10, 12, 2, 3, 6, 8, 9]])\n",
    "\n",
    "# Update network below to perform a multi-class classification with four labels\n",
    "model = nn.Sequential(\n",
    "  nn.Linear(11, 20),\n",
    "  nn.Linear(20, 12),\n",
    "  nn.Linear(12, 6),\n",
    "  nn.Linear(6, 4),\n",
    "  nn.Softmax(dim=-1)\n",
    ")\n",
    "\n",
    "output = model(input_tensor)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9e48cb-35f8-4998-b224-df3a946622c1",
   "metadata": {},
   "source": [
    "## Loss Function\n",
    "\n",
    "- Tells us how good our model is during training\n",
    "- Takes a model prediction *$\\hat{y}$* and ground truth *y*\n",
    "- Outputs a float\n",
    "\n",
    "**loss** = *F(y, $\\hat{y}$)*\n",
    "\n",
    "y is a single integer (class label)\n",
    "\n",
    "$\\hat{y}$ is a tensor (prediction before softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d1b9672-7ee3-442e-9033-c96a6ad95203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 0, 0])\n",
      "\n",
      " tensor([0, 1, 0])\n",
      "\n",
      " tensor([0, 0, 1])\n"
     ]
    }
   ],
   "source": [
    "# Transforming labels with one-hot encoding\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "print(F.one_hot(torch.tensor(0), num_classes = 3))\n",
    "\n",
    "print(\"\\n\", F.one_hot(torch.tensor(1), num_classes = 3))\n",
    "\n",
    "print(\"\\n\", F.one_hot(torch.tensor(2), num_classes = 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d45ebedb-f6b9-46d1-b8a9-66a496f93e22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(9.8222, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# Cross entropy loss in PyTorch\n",
    "\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "scores = torch.tensor([-5.2, 4.6, 0.8])\n",
    "one_hot_target = torch.tensor([1, 0, 0])\n",
    "criterion = CrossEntropyLoss()\n",
    "\n",
    "print(criterion(scores.double(), one_hot_target.double()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1c9d5aba-a416-43e1-9357-f9655d59cdb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-hot vector using NumPy: [0 1 0]\n",
      "One-hot vector using PyTorch: tensor([0, 1, 0])\n"
     ]
    }
   ],
   "source": [
    "# training ver 5\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "y = 1\n",
    "num_classes = 3\n",
    "\n",
    "# Create the one-hot encoded vector using NumPy\n",
    "one_hot_numpy = np.array([0, 1, 0])\n",
    "\n",
    "# Create the one-hot encoded vector using PyTorch\n",
    "one_hot_pytorch = F.one_hot(torch.tensor(y), num_classes=3)\n",
    "\n",
    "print(\"One-hot vector using NumPy:\", one_hot_numpy)\n",
    "print(\"One-hot vector using PyTorch:\", one_hot_pytorch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "86712388-7876-44d7-8a4a-73ed0300ab09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(8.0619, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# training ver 6\n",
    "\n",
    "y = [2]\n",
    "scores = torch.tensor([[0.1, 6.0, -2.0, 3.2]])\n",
    "\n",
    "# Create a one-hot encoded vector of the label y\n",
    "one_hot_label = F.one_hot(torch.tensor(y), num_classes=4)\n",
    "\n",
    "# Create the cross entropy loss function\n",
    "criterion = CrossEntropyLoss()\n",
    "\n",
    "# Calculate the cross entropy loss\n",
    "loss = criterion(scores.double(), one_hot_label.double())\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdeb7a97-f450-46c4-809f-0ffe5c06d6ac",
   "metadata": {},
   "source": [
    "## Backpropagation in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "501ede3b-ab0f-4b12-8c45-ef86a4f45faa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0 weight grad:\n",
      " tensor([[-0.0447,  0.0411,  0.0220,  0.0040,  0.0658,  0.0156,  0.0333,  0.0338,\n",
      "         -0.0132,  0.0699, -0.0336, -0.0146, -0.0129,  0.0273, -0.0432,  0.0111],\n",
      "        [ 0.0766, -0.0704, -0.0377, -0.0069, -0.1129, -0.0268, -0.0570, -0.0579,\n",
      "          0.0227, -0.1199,  0.0577,  0.0251,  0.0221, -0.0468,  0.0741, -0.0191],\n",
      "        [ 0.1172, -0.1078, -0.0578, -0.0105, -0.1728, -0.0410, -0.0873, -0.0886,\n",
      "          0.0347, -0.1836,  0.0883,  0.0384,  0.0338, -0.0717,  0.1135, -0.0292],\n",
      "        [-0.2169,  0.1995,  0.1069,  0.0195,  0.3198,  0.0759,  0.1616,  0.1641,\n",
      "         -0.0642,  0.3398, -0.1634, -0.0710, -0.0625,  0.1327, -0.2100,  0.0540],\n",
      "        [ 0.1375, -0.1265, -0.0678, -0.0123, -0.2027, -0.0481, -0.1024, -0.1040,\n",
      "          0.0407, -0.2154,  0.1036,  0.0450,  0.0396, -0.0841,  0.1331, -0.0342],\n",
      "        [-0.1167,  0.1074,  0.0575,  0.0105,  0.1721,  0.0409,  0.0870,  0.0883,\n",
      "         -0.0346,  0.1829, -0.0879, -0.0382, -0.0336,  0.0714, -0.1130,  0.0291],\n",
      "        [-0.0828,  0.0761,  0.0408,  0.0074,  0.1220,  0.0290,  0.0617,  0.0626,\n",
      "         -0.0245,  0.1297, -0.0624, -0.0271, -0.0238,  0.0506, -0.0801,  0.0206],\n",
      "        [-0.1158,  0.1065,  0.0571,  0.0104,  0.1706,  0.0405,  0.0862,  0.0875,\n",
      "         -0.0343,  0.1813, -0.0872, -0.0379, -0.0333,  0.0708, -0.1121,  0.0288]])\n",
      "Layer 0 bias grad:\n",
      " tensor([ 0.0288, -0.0494, -0.0756,  0.1400, -0.0887,  0.0753,  0.0534,  0.0747])\n",
      "Layer 1 weight grad:\n",
      " tensor([[-0.0694,  0.0773,  0.0151,  0.1541, -0.1040,  0.1076,  0.0718, -0.0360],\n",
      "        [ 0.0683, -0.0761, -0.0149, -0.1517,  0.1024, -0.1058, -0.0706,  0.0354],\n",
      "        [ 0.0596, -0.0664, -0.0130, -0.1324,  0.0894, -0.0924, -0.0617,  0.0309],\n",
      "        [-0.0070,  0.0078,  0.0015,  0.0156, -0.0105,  0.0109,  0.0073, -0.0036]])\n",
      "Layer 1 bias grad:\n",
      " tensor([-0.2247,  0.2211,  0.1930, -0.0227])\n",
      "Layer 2 weight grad:\n",
      " tensor([[-0.0023, -0.0361, -0.0143, -0.0742],\n",
      "        [ 0.0023,  0.0361,  0.0143,  0.0742]])\n",
      "Layer 2 bias grad:\n",
      " tensor([ 0.2914, -0.2914])\n"
     ]
    }
   ],
   "source": [
    "# Define a sample input tensor (batch size = 1, input features = 16)\n",
    "sample = torch.randn(1, 16)  # random float tensor with shape (1, 16)\n",
    "\n",
    "# Define a target tensor (class label index, should be a scalar for CrossEntropyLoss)\n",
    "target = torch.tensor([1])  # class index, assuming 2 classes: 0 or 1\n",
    "\n",
    "# Define the model\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(16, 8),\n",
    "    nn.Linear(8, 4),\n",
    "    nn.Linear(4, 2)\n",
    ")\n",
    "\n",
    "# Run a forward pass\n",
    "prediction = model(sample)\n",
    "\n",
    "# Calculate the loss and gradients\n",
    "criterion = CrossEntropyLoss()\n",
    "loss = criterion(prediction, target)\n",
    "loss.backward()\n",
    "\n",
    "# Access each layer's gradients\n",
    "print(\"Layer 0 weight grad:\\n\", model[0].weight.grad)\n",
    "print(\"Layer 0 bias grad:\\n\", model[0].bias.grad)\n",
    "print(\"Layer 1 weight grad:\\n\", model[1].weight.grad)\n",
    "print(\"Layer 1 bias grad:\\n\", model[1].bias.grad)\n",
    "print(\"Layer 2 weight grad:\\n\", model[2].weight.grad)\n",
    "print(\"Layer 2 bias grad:\\n\", model[2].bias.grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "74185100-023e-4134-ab24-38393f44450d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning rate is typically small\n",
    "lr = 0.001\n",
    "\n",
    "# Update the weights\n",
    "weight = model[0].weight\n",
    "weight_grad = model[0].weight.grad \n",
    "weight = weight - lr * weight_grad\n",
    "\n",
    "# Update the biases\n",
    "bias = model[0].bias\n",
    "bias_grad = model[0].bias.grad\n",
    "bias = bias - lr * bias_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "30a863a3-237c-44de-99ac-b8b6fe59307a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Descent\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "# Create the optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "# Perform parameter updates\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "380bfc57-0ff2-4b83-a7e7-9404d5ae5304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight of the first layer: Parameter containing:\n",
      "tensor([[-0.1036, -0.1248, -0.1848,  0.0141, -0.1558, -0.0666,  0.1544, -0.1820,\n",
      "          0.1267, -0.1320, -0.1446, -0.1575,  0.1177,  0.0787,  0.0488,  0.1520],\n",
      "        [ 0.1046,  0.0921, -0.1327,  0.2453, -0.0696, -0.2135,  0.0331, -0.1939,\n",
      "          0.2161,  0.1761,  0.1340, -0.1116, -0.0188, -0.1235,  0.0274, -0.1254],\n",
      "        [-0.1565, -0.2480, -0.1953,  0.0049, -0.1227, -0.1135,  0.2010,  0.0796,\n",
      "         -0.1304,  0.2435,  0.1611,  0.1908,  0.1889,  0.2149,  0.2492,  0.2395],\n",
      "        [ 0.1736,  0.1248, -0.0503,  0.1658,  0.0115,  0.0879, -0.1803,  0.1376,\n",
      "          0.0195, -0.1506,  0.1189,  0.0783,  0.2294,  0.1511,  0.1976,  0.2394],\n",
      "        [-0.1578, -0.0007, -0.2233,  0.2405, -0.1803, -0.0566,  0.2214, -0.0371,\n",
      "         -0.0817, -0.1036, -0.1219, -0.0834, -0.0039,  0.2437,  0.0330,  0.1861],\n",
      "        [ 0.1130, -0.0859, -0.0590, -0.0926, -0.2295,  0.1491, -0.1013, -0.2133,\n",
      "          0.1659,  0.2019,  0.0551,  0.2438,  0.0117, -0.1402, -0.0297,  0.1629],\n",
      "        [ 0.0431,  0.0032, -0.1865, -0.0789, -0.2220, -0.0979, -0.1803,  0.1518,\n",
      "          0.0048,  0.0815,  0.1846,  0.2478, -0.0666,  0.1711, -0.0223,  0.2471],\n",
      "        [ 0.0436,  0.1925, -0.0861,  0.0789,  0.1575, -0.1650, -0.1491,  0.0533,\n",
      "          0.1627, -0.0076,  0.2113, -0.1362, -0.2095, -0.2388,  0.1964, -0.1131]],\n",
      "       requires_grad=True)\n",
      "Bias of the second layer: Parameter containing:\n",
      "tensor([0.2186, 0.1561], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# taining ver 7\n",
    "\n",
    "model = nn.Sequential(nn.Linear(16, 8),\n",
    "                      nn.Linear(8, 2)\n",
    "                     )\n",
    "\n",
    "# Access the weight of the first linear layer\n",
    "weight_0 = model[0].weight\n",
    "print(\"Weight of the first layer:\", weight_0)\n",
    "\n",
    "# Access the bias of the second linear layer\n",
    "bias_1 = model[1].bias\n",
    "print(\"Bias of the second layer:\", bias_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2967bc04-2afa-4c9a-a2a5-db60e923e834",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training ver 8\n",
    "\n",
    "# weight0 = model[0].weight\n",
    "# weight1 = model[1].weight\n",
    "# weight2 = model[2].weight\n",
    "\n",
    "# # Access the gradients of the weight of each linear layer\n",
    "# grads0 = weight0.grad\n",
    "# grads1 = weight1.grad\n",
    "# grads2 = weight2.grad\n",
    "\n",
    "# Update the weights using the learning rate and the gradients\n",
    "# weight0 = weight0 - lr * grads0\n",
    "# weight1 = weight1 - lr * grads1\n",
    "# weight2 = weight2 - lr * grads2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7da40524-2bf6-4a95-a0dc-9bc32c12c654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training ver 9\n",
    "\n",
    "# Create the optimizer\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "# loss = criterion(pred, target)\n",
    "# loss.backward()\n",
    "\n",
    "# # Update the model's parameters using the optimizer\n",
    "# optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d64dca8-e690-4a75-862f-c59be421020c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
